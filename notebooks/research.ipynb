{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Store Sales - Time Series Forecasting\n",
    "\n",
    "Use machine learning to predict grocery sales. [source](https://www.kaggle.com/competitions/store-sales-time-series-forecasting/overview/description)\n",
    "\n",
    "## Objective\n",
    "\n",
    "In this Kaggle competition, the goal is to \n",
    "\n",
    "> build a model that more accurately predicts the unit sales for thousands of items sold at different Favorita stores.\n",
    "\n",
    "The evaluation metric for this competition is ***Root Mean Squared Logarithmic Error***.\n",
    "\n",
    "The `RMSLE` is calculated as:\n",
    "\n",
    "$$\\sqrt{ \\frac{1}{n} \\sum_{i=1}^n \\left(\\log (1 + \\hat{y}_i) - \\log (1 + y_i)\\right)^2}$$\n",
    "\n",
    "where:\n",
    "\n",
    "- $ n $ is the total number of instances,\n",
    "     \n",
    "- $\\hat{y}$ is the predicted value of the target for instance (i),\n",
    "   \n",
    "- $y_i$ is the actual value of the target for instance (i), and,\n",
    " \n",
    "- $log$ is the natural logarithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each id in the test set, you must predict a value for the sales variable. The file should contain a header and have the following format:\n",
    "\n",
    "    ```\n",
    "    id,sales\n",
    "    3000888,0.0\n",
    "    3000889,0.0\n",
    "    3000890,0.0\n",
    "    3000891,0.0\n",
    "    3000892,0.0\n",
    "    etc.\n",
    "    ```\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries for this research notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_file_path is /home/ubuntu/repos/time-series-forecasting/notebooks\n",
      "src_folder_path is /home/ubuntu/repos/time-series-forecasting/src\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# to overcome path issue for src\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "# set the path to the current file\n",
    "current_file_path = Path().resolve()\n",
    "print(f\"current_file_path is {current_file_path}\")\n",
    "\n",
    "# set the path to the src folder\n",
    "src_folder_path = current_file_path.parent / 'src'\n",
    "print(f\"src_folder_path is {src_folder_path}\")\n",
    "\n",
    "# add the src folder to the system path\n",
    "sys.path.append(str(src_folder_path))\n",
    "\n",
    "from data_loader import DBDataLoader\n",
    "from logger import logging"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Ingestion\n",
    "\n",
    "Query data from MySQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in data set using .sql file\n",
    "query_file_path = '../src/scripts/train_store_hols.sql'\n",
    "\n",
    "db = DBDataLoader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset from database...\n",
      "chunks size: 112\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d36e0879f9b94bb69c15958e28fdadb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Reading from DB:   0%|          | 0/112 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open(query_file_path, 'r') as query:\n",
    "    chunks = db.load(query=query.read())\n",
    "    # count += 1\n",
    "    print(f'chunks size: {sys.getsizeof(chunks)}')\n",
    "    logging.info(f\"chunks loaded {sys.getsizeof(chunks)}\")\n",
    "    df = pd.DataFrame()\n",
    "    for i in tqdm(range(sys.getsizeof(chunks)), desc='Reading from DB'):\n",
    "        for chunk in chunks:\n",
    "            df = pd.concat([df, chunk])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1972674, 15)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1972674 entries, 0 to 2673\n",
      "Data columns (total 15 columns):\n",
      " #   Column       Dtype         \n",
      "---  ------       -----         \n",
      " 0   id           int64         \n",
      " 1   family       object        \n",
      " 2   sales        float64       \n",
      " 3   onpromotion  int64         \n",
      " 4   city         object        \n",
      " 5   state        object        \n",
      " 6   cluster      int64         \n",
      " 7   locale       object        \n",
      " 8   locale_name  object        \n",
      " 9   description  object        \n",
      " 10  transferred  object        \n",
      " 11  type         object        \n",
      " 12  hol_type     object        \n",
      " 13  store_nbr    int64         \n",
      " 14  date         datetime64[ns]\n",
      "dtypes: datetime64[ns](1), float64(1), int64(4), object(9)\n",
      "memory usage: 240.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DF loaded confirm: 1972674 rows × 14 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset from database...\n",
      "VwDump1 chunks size: 112\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45a7a75630ae4714bf33db363791ed9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Reading from View:   0%|          | 0/112 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stmt='select * from VwDump1'\n",
    "\n",
    "chunks = db.load(query=stmt)\n",
    "\n",
    "print(f'VwDump1 chunks size: {sys.getsizeof(chunks)}')\n",
    "logging.info(f\"VwDump1 chunks loaded {sys.getsizeof(chunks)}\")\n",
    "\n",
    "view_df = pd.DataFrame()\n",
    "for i in tqdm(range(sys.getsizeof(chunks)), desc='Reading from View'):\n",
    "    for chunk in chunks:\n",
    "        view_df = pd.concat([view_df, chunk])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>family</th>\n",
       "      <th>sales</th>\n",
       "      <th>onpromotion</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>type</th>\n",
       "      <th>cluster</th>\n",
       "      <th>transactions</th>\n",
       "      <th>is_city_holiday</th>\n",
       "      <th>is_regional_holiday</th>\n",
       "      <th>is_national_holiday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>561</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>25</td>\n",
       "      <td>AUTOMOTIVE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Salinas</td>\n",
       "      <td>Santa Elena</td>\n",
       "      <td>D</td>\n",
       "      <td>1</td>\n",
       "      <td>770.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>562</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>25</td>\n",
       "      <td>BABY CARE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Salinas</td>\n",
       "      <td>Santa Elena</td>\n",
       "      <td>D</td>\n",
       "      <td>1</td>\n",
       "      <td>770.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>563</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>25</td>\n",
       "      <td>BEAUTY</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Salinas</td>\n",
       "      <td>Santa Elena</td>\n",
       "      <td>D</td>\n",
       "      <td>1</td>\n",
       "      <td>770.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>564</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>25</td>\n",
       "      <td>BEVERAGES</td>\n",
       "      <td>810.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Salinas</td>\n",
       "      <td>Santa Elena</td>\n",
       "      <td>D</td>\n",
       "      <td>1</td>\n",
       "      <td>770.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>565</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>25</td>\n",
       "      <td>BOOKS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Salinas</td>\n",
       "      <td>Santa Elena</td>\n",
       "      <td>D</td>\n",
       "      <td>1</td>\n",
       "      <td>770.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id       date  store_nbr      family  sales  onpromotion     city  \\\n",
       "0  561 2013-01-01         25  AUTOMOTIVE    0.0            0  Salinas   \n",
       "1  562 2013-01-01         25   BABY CARE    0.0            0  Salinas   \n",
       "2  563 2013-01-01         25      BEAUTY    2.0            0  Salinas   \n",
       "3  564 2013-01-01         25   BEVERAGES  810.0            0  Salinas   \n",
       "4  565 2013-01-01         25       BOOKS    0.0            0  Salinas   \n",
       "\n",
       "         state type  cluster  transactions  is_city_holiday  \\\n",
       "0  Santa Elena    D        1         770.0                0   \n",
       "1  Santa Elena    D        1         770.0                0   \n",
       "2  Santa Elena    D        1         770.0                0   \n",
       "3  Santa Elena    D        1         770.0                0   \n",
       "4  Santa Elena    D        1         770.0                0   \n",
       "\n",
       "   is_regional_holiday  is_national_holiday  \n",
       "0                    0                    1  \n",
       "1                    0                    1  \n",
       "2                    0                    1  \n",
       "3                    0                    1  \n",
       "4                    0                    1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "view_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DF loaded confirm: 3000888 rows × 14 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3000888 entries, 0 to 887\n",
      "Data columns (total 14 columns):\n",
      " #   Column               Dtype         \n",
      "---  ------               -----         \n",
      " 0   id                   int64         \n",
      " 1   date                 datetime64[ns]\n",
      " 2   store_nbr            int64         \n",
      " 3   family               object        \n",
      " 4   sales                float64       \n",
      " 5   onpromotion          int64         \n",
      " 6   city                 object        \n",
      " 7   state                object        \n",
      " 8   type                 object        \n",
      " 9   cluster              int64         \n",
      " 10  transactions         float64       \n",
      " 11  is_city_holiday      int64         \n",
      " 12  is_regional_holiday  int64         \n",
      " 13  is_national_holiday  int64         \n",
      "dtypes: datetime64[ns](1), float64(2), int64(7), object(4)\n",
      "memory usage: 343.4+ MB\n"
     ]
    }
   ],
   "source": [
    "view_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date'] = pd.to_datetime(df['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index('date', drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 1972674 entries, 2013-01-01 to 2015-12-31\n",
      "Data columns (total 14 columns):\n",
      " #   Column       Dtype  \n",
      "---  ------       -----  \n",
      " 0   id           int64  \n",
      " 1   family       object \n",
      " 2   sales        float64\n",
      " 3   onpromotion  int64  \n",
      " 4   city         object \n",
      " 5   state        object \n",
      " 6   cluster      int64  \n",
      " 7   locale       object \n",
      " 8   locale_name  object \n",
      " 9   description  object \n",
      " 10  transferred  object \n",
      " 11  type         object \n",
      " 12  hol_type     object \n",
      " 13  store_nbr    int64  \n",
      "dtypes: float64(1), int64(4), object(9)\n",
      "memory usage: 225.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "view_df.drop('id', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupby_store = view_df.groupby(by=['store_nbr', 'family'], group_keys=True).agg('sum', 'mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 1782 entries, (1, 'AUTOMOTIVE') to (54, 'SEAFOOD')\n",
      "Data columns (total 7 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   sales                1782 non-null   float64\n",
      " 1   onpromotion          1782 non-null   int64  \n",
      " 2   cluster              1782 non-null   int64  \n",
      " 3   transactions         1782 non-null   float64\n",
      " 4   is_city_holiday      1782 non-null   int64  \n",
      " 5   is_regional_holiday  1782 non-null   int64  \n",
      " 6   is_national_holiday  1782 non-null   int64  \n",
      "dtypes: float64(2), int64(5)\n",
      "memory usage: 101.7+ KB\n"
     ]
    }
   ],
   "source": [
    "groupby_store.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ydata_profiling import ProfileReport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6843931a89794337bce593db3c60190d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Summarize dataset:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniforge3/envs/forecasting/lib/python3.9/site-packages/ydata_profiling/model/pandas/correlations_pandas.py:84: FutureWarning: reindexing with a non-unique Index is deprecated and will raise in a future version.\n",
      "  return _cramers_corrected_stat(pd.crosstab(col_1, col_2), correction=True)\n",
      "/home/ubuntu/miniforge3/envs/forecasting/lib/python3.9/site-packages/ydata_profiling/model/correlations.py:66: UserWarning: There was an attempt to calculate the auto correlation, but this failed.\n",
      "To hide this warning, disable the calculation\n",
      "(using `df.profile_report(correlations={\"auto\": {\"calculate\": False}})`\n",
      "If this is problematic for your use case, please report this as an issue:\n",
      "https://github.com/ydataai/ydata-profiling/issues\n",
      "(include the error message: 'cannot reindex on an axis with duplicate labels')\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dcf8cf320ba42f99c2895f84616b53c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generate report structure:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f64f46fcc0354836a9dc8c416c9eedfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Render HTML:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff322d8e2cd8473aa5c005f1a10e7020",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Export report to file:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "profile = ProfileReport(view_df, title=\"ProfileReport view_df\")\n",
    "# profile.to_notebook_iframe()\n",
    "profile.to_file(\"../artifacts/reports/view_df_ProfileReport.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniforge3/envs/forecasting/lib/python3.9/site-packages/numba/core/decorators.py:262: NumbaDeprecationWarning: \u001b[1mnumba.generated_jit is deprecated. Please see the documentation at: https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-generated-jit for more information and advice on a suitable replacement.\u001b[0m\n",
      "  warnings.warn(msg, NumbaDeprecationWarning)\n",
      "/home/ubuntu/miniforge3/envs/forecasting/lib/python3.9/site-packages/visions/backends/shared/nan_handling.py:51: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def hasna(x: np.ndarray) -> bool:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9866d73c8dd442bcaff8493bb63ce837",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Summarize dataset:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniforge3/envs/forecasting/lib/python3.9/site-packages/ydata_profiling/model/pandas/correlations_pandas.py:84: FutureWarning: reindexing with a non-unique Index is deprecated and will raise in a future version.\n",
      "  return _cramers_corrected_stat(pd.crosstab(col_1, col_2), correction=True)\n",
      "/home/ubuntu/miniforge3/envs/forecasting/lib/python3.9/site-packages/ydata_profiling/model/correlations.py:66: UserWarning: There was an attempt to calculate the auto correlation, but this failed.\n",
      "To hide this warning, disable the calculation\n",
      "(using `df.profile_report(correlations={\"auto\": {\"calculate\": False}})`\n",
      "If this is problematic for your use case, please report this as an issue:\n",
      "https://github.com/ydataai/ydata-profiling/issues\n",
      "(include the error message: 'cannot reindex on an axis with duplicate labels')\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afe34d7bd6e849c0a69c97dbc24ec1cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generate report structure:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47126271fc8d416caa8da97b06ebf883",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Render HTML:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "baf01999d0aa444386eac8640bab9ee8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Export report to file:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "profile = ProfileReport(df, title=\"ProfileReport defaults\")\n",
    "# profile.to_notebook_iframe()\n",
    "profile.to_file(\"../artifacts/reports/df_ProfileReport.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
